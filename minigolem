#!/usr/bin/env python2

""" Parse Kbuild makefiles to extract configurability information."""

# Copyright (C) 2014-2015 Andreas Ruprecht <andreas.ruprecht@fau.de>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

import argparse
import collections
import importlib
import logging
import os
import re
import sys
import types

sys.path = [os.path.join(os.path.dirname(sys.path[0]), 'lib',
                         'python%d.%d' % (sys.version_info[0],
                                          sys.version_info[1]),
                         'site-packages')] + sys.path

import vamos.model as Model
import vamos.tools as Tools
import kbuildparse.base_classes as BaseClasses
import kbuildparse.data_structures as DataStructures
import vamos.golem.kbuild as Kbuild

def parse_args(argv):
    """ Helper function to parse command line arguments and initialize
    the logger. """
    arguments = argparse.ArgumentParser(description="Parser for Kbuild files")

    arguments.add_argument('-v', '--verbose', help="increase the log level " +
                           "(can be specified multiple times)", action="count")

    arguments.add_argument('-q', help="decrease the log level", action="count")

    arguments.add_argument('-a', '--arch', help="target architecture",
                           default=None)

    arguments.add_argument('-m', '--model', help="specify the model file",
                           default=None)

    arguments.add_argument('-c', '--classes', help="subdirectory where parser" +
                           " class extensions should be searched", default=None)

    arguments.add_argument('directory', help="input directories containing " +
                           "Kbuild/Makefiles", nargs="*")

    arguments.add_argument('--check', help=argparse.SUPPRESS,
                           action="store_true", default=False)

    args = arguments.parse_args(argv)
    Tools.setup_logging(args.verbose)
    return args


class KbuildParser(object):
    """ Main class: parse Kbuild files recursively."""

    def __init__(self, model=None, arch=None):
        """ Initialize the parser. We need a model for _MODULE options."""
        self.model = model
        self.arch = arch
        self.local_vars = DataStructures.VariableStore()
        self.global_vars = DataStructures.VariableStore()
        self.init_class = None
        self.before_pass = []
        self.during_pass = []
        self.after_pass = []
        self.before_exit = []
        self.file_content_cache = {}

    def enter_new_symbolic_level(self):
        """ Get a fresh mapping for variables, save old mapping in nxt."""
        new_store = DataStructures.VariableStore()
        new_store.nxt = self.local_vars
        self.local_vars = new_store

    def leave_symbolic_level(self):
        """ Restore old mapping from local_vars.nxt."""
        assert self.local_vars.nxt is not None
        self.local_vars = self.local_vars.nxt

    def process_kbuild_or_makefile(self, path, conditions):
        """ Central processing function. Parse the file in @path which
        has preconditions @conditions. Processing is done by classes which
        have previously been gathered in corresponding lists."""

        if not os.path.isfile(path):
            return

        basepath = os.path.dirname(path)

        # Create new symbol table for local variables
        self.enter_new_symbolic_level()

        # Execute BeforePass subclass functions
        for processor in self.before_pass:
            processor.process(self, basepath)

        self.read_whole_file(path)

        # Main processing loop, iteration over file
        for line in self.file_content_cache[path]:
            # Execute DuringPass module functions
            for processor in self.during_pass:
                # As soon as one method returns True, continue with next line
                if processor.process(self, line, basepath):
                    break
        # End of main processing loop

        # Execute subclasses of AfterPass
        for processor in self.after_pass:
            processor.process(self, path, conditions)

        # Drop current symbol table
        self.leave_symbolic_level()

    def read_whole_file(self, path):
        """ Read the content of the file in @path into the file_content_cache
        dictionary. Include statements are resolved on-the-fly (see comment in
        resolve_includes())."""
        output = []
        with open(path, "r") as infile:
            dirname = os.path.dirname(path)
            while True:
                (good, line) = Tools.get_multiline_from_file(infile)
                if not good:
                    break
                inputs = self.resolve_includes(line, dirname)
                output.extend(inputs)

        self.file_content_cache[path] = output

    def resolve_includes(self, line, srcpath):
        """ If @line starts with "include", read all the lines in the included
        file. This is done recursively to treat recursive includes. The @srcpath
        parameter is needed to correctly resolve the $(src) variable in the
        included files (it needs to contain the path to the folder of the
        top-most including Makefile)."""
        if not line.startswith("include "):
            return [DataStructures.LineObject(line)]

        line = re.sub(r"\$\(src\)", srcpath, line)
        lines = []

        target = line.split(" ")[1].rstrip()
        if not os.path.isfile(target):
            return lines

        with open(target, "r") as infile:
            while True:
                (good, line) = Tools.get_multiline_from_file(infile)
                if not good:
                    break
                lines.extend(self.resolve_includes(line, srcpath))

        return lines


def main(argv):
    """ Main function to kick everything off."""
    #pylint: disable=R0912
    #pylint: disable=R0914
    #pylint: disable=R0915

    args = parse_args(argv)
    project = None
    arch = args.arch

    if args.check:
    # For validation tests
        arch = "test"
        project = "linux"
    elif Kbuild.is_linux():
    # Check if we're inside a Linux tree
        logging.info("Detected a Linux tree")
        if not args.arch:
            sys.exit("E: architecture to analyze must be provided")
        project = "linux"
    elif Kbuild.is_busybox():
    # If it was not Linux, maybe it was busybox?
        logging.info("Detected a Busybox tree")
        arch = 'busybox'
        project = "busybox"
    elif Kbuild.is_coreboot():
    # ... or maybe coreboot?
        logging.info("Detected a Coreboot tree")
        arch = 'coreboot'
        project = "coreboot"

    if args.model:
        modelfile = args.model
        if not os.path.isfile(modelfile):
            sys.exit("E: specified model \"%s\" not found" % modelfile)
    else:
        modelfile = Model.get_model_for_arch(arch)
        if not modelfile:
            sys.exit("E: Model for arch %s not found, generate models using " \
                     "undertaker-kconfigdump or specify a model (-m)" % arch)

    read_model = Model.parse_model(modelfile, shallow=True)
    parser = KbuildParser(read_model, arch)

    dirs_to_process = collections.OrderedDict()

    # Default to the project default parser if -c was not given
    if project and not args.classes:
        project_module = importlib.import_module("kbuildparse" + "." + project)
        args.classes = os.path.dirname(project_module.__file__)

    if args.classes:
        additional_path = os.path.abspath(args.classes)
        sys.path.append(additional_path)

        # Ignore these modules when loading. This is needed, because
        # subclass(A, A) == True. We can also avoid unnecessary loading
        # and checking with this.
        to_ignore = [x for (_, x) in BaseClasses.__dict__.items() +
                     DataStructures.__dict__.items()]

        # Iterate over additional Python files
        for pyfile in os.listdir(additional_path):
            # Ignore internal files and non-Python files
            if not pyfile.endswith(".py") or pyfile.startswith("__"):
                continue

            module = importlib.import_module(pyfile[:-3])
            for (name, cls) in sorted(module.__dict__.items()):
                # Don't consider internal classes from the file
                if name.startswith("__"):
                    continue

                # If we ignore it or don't have a class at all, continue
                if cls in to_ignore or not type(cls) is types.TypeType:
                    continue
                # Load classes into respective lists
                if issubclass(cls, BaseClasses.InitClass):
                    if parser.init_class is not None:
                        sys.exit("E: multiple init classes provided!")
                    parser.init_class = cls(read_model, args.arch)
                elif issubclass(cls, BaseClasses.BeforePass):
                    parser.before_pass.append(cls(read_model, args.arch))
                elif issubclass(cls, BaseClasses.DuringPass):
                    parser.during_pass.append(cls(read_model, args.arch))
                elif issubclass(cls, BaseClasses.AfterPass):
                    parser.after_pass.append(cls(read_model, args.arch))
                elif issubclass(cls, BaseClasses.BeforeExit):
                    parser.before_exit.append(cls(read_model, args.arch))
                else:
                    logging.warning("W: unknown class %s found!", name)

    # Execute subclass of InitClass
    if parser.init_class is None:
        sys.exit("E: no initializer module provided!")

    parser.init_class.process(parser, args, dirs_to_process)

    # Descend into subdirectories
    for item in dirs_to_process:
        descend = parser.init_class.get_file_for_subdirectory(item)
        logging.debug("Descending into " + descend)
        parser.process_kbuild_or_makefile(descend, dirs_to_process[item])

    # Execute subclasses of BeforeExit
    for processor in parser.before_exit:
        processor.process(parser)

if __name__ == "__main__":
    main(sys.argv[1:])
